# LLM Engine Selection
ENGINE=GEMINI  # or LLAMA_CPP

# Gemini Configuration
GEMINI_API_KEY=your_api_key_here
MODEL_NAME=gemini-2.5-flash

# LLaMA Configuration (if ENGINE=LLAMA_CPP)
LLAMA_MODEL_PATH=/path/to/model.gguf
LLAMA_GPU_LAYERS=1
LLAMA_CONTEXT_SIZE=2048
LLAMA_TEMPERATURE=0.7
LLAMA_TOP_P=0.9
LLAMA_TOP_K=40